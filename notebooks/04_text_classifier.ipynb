{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71274ed0",
   "metadata": {},
   "source": [
    "# TEXT CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d11070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT DOCUMENT PROCESSOR\n",
      "==================================================\n",
      "Initialized CSV files: ../csv_classifier/invoice_ocr.csv, ../csv_classifier/receipt_ocr.csv\n",
      "Processing text file: ../temp/detected/doc_content.txt\n",
      "Classification scores - Invoice: 6, Receipt: 0\n",
      "Document classified as: INVOICE\n",
      "\n",
      "Extracted Information:\n",
      "   Document No: 8l202510003\n",
      "   Date: 17/09/2025\n",
      "   Seller: บริษัทโกลบอลโซลูชัน จำกัด\n",
      "   Total: 53500.0\n",
      "   Items: ค่าบริการดูแลระบบ cloud, ค่าออกแบบเว็ปไซต์ใหม่\n",
      "Overwritten JSON: invoice - 20250922_181623_395753\n",
      "Appended to CSV: ../csv_classifier/invoice_ocr.csv\n",
      "Document processed successfully\n",
      "\n",
      "============================================================\n",
      "TEXT DOCUMENT PROCESSING SUMMARY\n",
      "============================================================\n",
      "Total Documents Processed: 1\n",
      "Invoices: 1\n",
      "Receipts: 0\n",
      "\n",
      "Latest Invoice:\n",
      "  source_file: ../temp/detected/doc_content.txt\n",
      "  document_type: invoice\n",
      "  processed_timestamp: 2025-09-22T18:16:23.395753\n",
      "  invoice_no: 8l202510003\n",
      "  invoice_date: 17/09/2025\n",
      "  due_date: 11/09/2025\n",
      "  seller_name: บริษัทโกลบอลโซลูชัน จำกัด\n",
      "  seller_tax_id: 0105559999999\n",
      "  buyer_name: บริษัท ดิจิทัลเทคโนโลยีไทย จำกัด\n",
      "  buyer_tax_id: 0105558888888\n",
      "  item_description: ค่าบริการดูแลระบบ cloud, ค่าออกแบบเว็ปไซต์ใหม่\n",
      "  item_quantity: 2\n",
      "  subtotal: 50000.0\n",
      "  vat_amount: 3500.0\n",
      "  total_amount: 53500.0\n",
      "  currency: THB\n",
      "\n",
      "Output Files:\n",
      "  JSON: ../meta_data/meta.json\n",
      "  Invoice CSV: ../csv_classifier/invoice_ocr.csv\n",
      "  Receipt CSV: ../csv_classifier/receipt_ocr.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parks\\AppData\\Local\\Temp\\ipykernel_12264\\1715633065.py:467: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class TextDocumentProcessor:\n",
    "    \"\"\"\n",
    "    Process text files to classify documents and extract key information\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.json_storage_path = \"../meta_data/meta.json\"\n",
    "        self.invoice_csv_path = \"../csv_classifier/invoice_ocr.csv\" \n",
    "        self.receipt_csv_path = \"../csv_classifier/receipt_ocr.csv\"\n",
    "        \n",
    "        # Initialize storage\n",
    "        self._init_storage()\n",
    "    \n",
    "    def _init_storage(self):\n",
    "        \"\"\"Initialize JSON and CSV storage files\"\"\"\n",
    "        # Create directories\n",
    "        Path(\"../meta_data\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(\"../csv_classifier\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize JSON file (always recreate if corrupted)\n",
    "        try:\n",
    "            if os.path.exists(self.json_storage_path):\n",
    "                with open(self.json_storage_path, 'r', encoding='utf-8') as f:\n",
    "                    json.load(f)  # Test if file is valid JSON\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            # Create/recreate if corrupted or missing\n",
    "            initial_data = {\n",
    "                \"invoices\": [],\n",
    "                \"receipts\": [],\n",
    "                \"processing_history\": []\n",
    "            }\n",
    "            with open(self.json_storage_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(initial_data, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"Initialized JSON file: {self.json_storage_path}\")\n",
    "        \n",
    "        # Initialize CSV files with proper headers\n",
    "        invoice_columns = [\n",
    "            'invoice_no', 'invoice_date', 'due_date', 'seller_name', 'seller_tax_id',\n",
    "            'buyer_name', 'buyer_tax_id', 'item_description', 'item_quantity', \n",
    "            'item_unit_price', 'subtotal', 'vat_amount', 'total_amount', 'currency',\n",
    "            'notes', 'processed_timestamp'\n",
    "        ]\n",
    "        \n",
    "        receipt_columns = [\n",
    "            'receipt_no', 'receipt_date', 'seller_name', 'seller_tax_id', 'buyer_name',\n",
    "            'payment_method', 'item_description', 'item_quantity', 'item_unit_price',\n",
    "            'subtotal', 'vat_amount', 'total_paid', 'currency', 'acknowledgement',\n",
    "            'processed_timestamp'\n",
    "        ]\n",
    "        \n",
    "        # Force recreate CSV files to ensure proper headers\n",
    "        pd.DataFrame(columns=invoice_columns).to_csv(self.invoice_csv_path, index=False, encoding='utf-8')\n",
    "        pd.DataFrame(columns=receipt_columns).to_csv(self.receipt_csv_path, index=False, encoding='utf-8')\n",
    "        print(f\"Initialized CSV files: {self.invoice_csv_path}, {self.receipt_csv_path}\")\n",
    "    \n",
    "    def classify_document(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Classify document as invoice or receipt based on text content\n",
    "        \n",
    "        Args:\n",
    "            text (str): Full text content of document\n",
    "            \n",
    "        Returns:\n",
    "            str: 'invoice' or 'receipt'\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        invoice_score = 0\n",
    "        receipt_score = 0\n",
    "        \n",
    "        # Enhanced keyword scoring\n",
    "        invoice_keywords = [\n",
    "            'ใบแจ้งหนี้', 'invoice', 'วันครบกำหนด', 'due date', \n",
    "            'ผู้ซื้อ', 'ผู้รับในแจ้งหนี้', 'bl', 'inv', 'quotation',\n",
    "            'ใบเสนอราคา', 'proposal', 'estimate'\n",
    "        ]\n",
    "        receipt_keywords = [\n",
    "            'ใบเสร็จ', 'receipt', 'pos', 'ขอบคุณ', 'thank you',\n",
    "            'ได้รับเงิน', 'ชำระเงิน', 'paid', 'payment received',\n",
    "            'cash', 'credit card', 'transfer'\n",
    "        ]\n",
    "        \n",
    "        # Count keyword occurrences\n",
    "        for keyword in invoice_keywords:\n",
    "            if keyword in text_lower:\n",
    "                invoice_score += 2\n",
    "                \n",
    "        for keyword in receipt_keywords:\n",
    "            if keyword in text_lower:\n",
    "                receipt_score += 2\n",
    "        \n",
    "        # Check for document number patterns\n",
    "        if re.search(r'(?:inv|bl|qt)[\\-\\s]*\\d+', text_lower):\n",
    "            invoice_score += 3\n",
    "        if re.search(r'(?:rc|pos|rec)[\\-\\s]*\\d+', text_lower):\n",
    "            receipt_score += 3\n",
    "        \n",
    "        # Check for payment confirmation phrases\n",
    "        payment_phrases = ['ได้รับเงินแล้ว', 'payment completed', 'paid in full']\n",
    "        for phrase in payment_phrases:\n",
    "            if phrase in text_lower:\n",
    "                receipt_score += 3\n",
    "        \n",
    "        # Check for due date (common in invoices)\n",
    "        if 'due' in text_lower or 'ครบกำหนด' in text_lower:\n",
    "            invoice_score += 2\n",
    "        \n",
    "        print(f\"Classification scores - Invoice: {invoice_score}, Receipt: {receipt_score}\")\n",
    "        \n",
    "        return 'invoice' if invoice_score > receipt_score else 'receipt'\n",
    "    \n",
    "    def extract_document_numbers(self, text: str) -> str:\n",
    "        \"\"\"Extract document numbers from text\"\"\"\n",
    "        patterns = [\n",
    "            r'เลขที่\\s*:?\\s*([A-Z0-9\\-]+)',\n",
    "            r'(?:invoice|inv|bl|qt|rc|pos|receipt)\\s*(?:no\\.?|#)?\\s*:?\\s*([A-Z0-9\\-]+)',\n",
    "            r'(?:BL|INV|QT|RC|POS)(\\d+)',\n",
    "            r'(?:R-|RC)(\\d{8}-\\d{3})',\n",
    "            r'หมายเลข\\s*:?\\s*([A-Z0-9\\-]+)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_dates(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract dates from text\"\"\"\n",
    "        result = {'document_date': None, 'due_date': None}\n",
    "        \n",
    "        thai_months = {\n",
    "            'มกราคม': '01', 'ม.ค.': '01', 'jan': '01', 'january': '01',\n",
    "            'กุมภาพันธ์': '02', 'ก.พ.': '02', 'feb': '02', 'february': '02',\n",
    "            'มีนาคม': '03', 'มี.ค.': '03', 'mar': '03', 'march': '03',\n",
    "            'เมษายน': '04', 'เม.ย.': '04', 'apr': '04', 'april': '04',\n",
    "            'พฤษภาคม': '05', 'พ.ค.': '05', 'may': '05',\n",
    "            'มิถุนายน': '06', 'มิ.ย.': '06', 'jun': '06', 'june': '06',\n",
    "            'กรกฎาคม': '07', 'ก.ค.': '07', 'jul': '07', 'july': '07',\n",
    "            'สิงหาคม': '08', 'ส.ค.': '08', 'aug': '08', 'august': '08',\n",
    "            'กันยายน': '09', 'ก.ย.': '09', 'sep': '09', 'september': '09',\n",
    "            'ตุลาคม': '10', 'ต.ค.': '10', 'oct': '10', 'october': '10',\n",
    "            'พฤศจิกายน': '11', 'พ.ย.': '11', 'nov': '11', 'november': '11',\n",
    "            'ธันวาคม': '12', 'ธ.ค.': '12', 'dec': '12', 'december': '12'\n",
    "        }\n",
    "        \n",
    "        date_patterns = [\n",
    "            r'(\\d{1,2})[\\/\\-\\.](\\d{1,2})[\\/\\-\\.](\\d{4})',\n",
    "            r'(\\d{1,2})\\s+(มกราคม|กุมภาพันธ์|มีนาคม|เมษายน|พฤษภาคม|มิถุนายน|กรกฎาคม|สิงหาคม|กันยายน|ตุลาคม|พฤศจิกายน|ธันวาคม|ม\\.ค\\.|ก\\.พ\\.|มี\\.ค\\.|เม\\.ย\\.|พ\\.ค\\.|มิ\\.ย\\.|ก\\.ค\\.|ส\\.ค\\.|ก\\.ย\\.|ต\\.ค\\.|พ\\.ย\\.|ธ\\.ค\\.)\\s+(\\d{4})',\n",
    "            r'(\\d{1,2})\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\\s+(\\d{4})'\n",
    "        ]\n",
    "        \n",
    "        for pattern in date_patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    groups = match.groups()\n",
    "                    day = groups[0]\n",
    "                    month = groups[1]\n",
    "                    year = groups[2]\n",
    "                    \n",
    "                    # Convert Thai month if needed\n",
    "                    if month.lower() in thai_months:\n",
    "                        month = thai_months[month.lower()]\n",
    "                    elif not month.isdigit():\n",
    "                        # Try to convert English month names\n",
    "                        month_lower = month.lower()\n",
    "                        if month_lower in thai_months:\n",
    "                            month = thai_months[month_lower]\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "                    # Convert Buddhist year to Christian year\n",
    "                    year = int(year)\n",
    "                    if year > 2500:\n",
    "                        year -= 543\n",
    "                    \n",
    "                    formatted_date = f\"{int(day):02d}/{int(month):02d}/{year}\"\n",
    "                    \n",
    "                    # Determine context\n",
    "                    start_pos = max(0, match.start() - 50)\n",
    "                    end_pos = min(len(text), match.end() + 50)\n",
    "                    context = text[start_pos:end_pos].lower()\n",
    "                    \n",
    "                    if any(word in context for word in ['ครบกำหนด', 'due', 'payment due']):\n",
    "                        result['due_date'] = formatted_date\n",
    "                    else:\n",
    "                        if not result['document_date']:\n",
    "                            result['document_date'] = formatted_date\n",
    "                        elif not result['due_date']:\n",
    "                            result['due_date'] = formatted_date\n",
    "                    \n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_entities(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract company names and tax IDs\"\"\"\n",
    "        result = {\n",
    "            'seller_name': None, \n",
    "            'seller_tax_id': None,\n",
    "            'buyer_name': None,\n",
    "            'buyer_tax_id': None\n",
    "        }\n",
    "        \n",
    "        # Extract tax IDs (13 digits)\n",
    "        tax_ids = re.findall(r'(\\d{13})', text)\n",
    "        \n",
    "        # Extract company names\n",
    "        company_patterns = [\n",
    "            r'บริษัท\\s+([^จำกัด\\n]+(?:จำกัด)?(?:\\s*\\(มหาชน\\))?)',\n",
    "            r'ห้างหุ้นส่วน\\s+([^\\n]+)',\n",
    "            r'([A-Z][a-zA-Z\\s&]+(?:Co\\.|Ltd\\.|Inc\\.|Corp\\.|Company|Limited))',\n",
    "            r'ร้าน\\s*([^\\n]+)',\n",
    "            r'([ก-๙\\s]+(?:จำกัด|มหาชน))'\n",
    "        ]\n",
    "        \n",
    "        company_names = []\n",
    "        for pattern in company_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                clean_name = match.strip()\n",
    "                if len(clean_name) > 3:  # Filter out very short matches\n",
    "                    company_names.append(clean_name)\n",
    "        \n",
    "        # Assign first found values\n",
    "        if tax_ids:\n",
    "            result['seller_tax_id'] = tax_ids[0]\n",
    "            if len(tax_ids) > 1:\n",
    "                result['buyer_tax_id'] = tax_ids[1]\n",
    "                \n",
    "        if company_names:\n",
    "            result['seller_name'] = company_names[0]\n",
    "            if len(company_names) > 1:\n",
    "                result['buyer_name'] = company_names[1]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_amounts(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Extract monetary amounts with improved parsing\"\"\"\n",
    "        result = {'subtotal': None, 'vat_amount': None, 'total_amount': None}\n",
    "        \n",
    "        # Specific amount patterns with context - more precise patterns\n",
    "        patterns = [\n",
    "            (r'รวมเป็นเงิน\\s*\\(ไม่รวม\\s*vat\\)\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)(?:\\s*บาท)?', 'subtotal'),\n",
    "            (r'ภาษีมูลค่าเพิ่ม.*?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)(?:\\s*บาท)?', 'vat_amount'),\n",
    "            (r'ยอดรวมสุทธิ\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)(?:\\s*บาท)?', 'total_amount'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, amount_type in patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    amount_str = match.group(1).replace(',', '')\n",
    "                    amount = float(amount_str)\n",
    "                    result[amount_type] = amount\n",
    "                    break  # Take first match for each type\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        # Calculate missing VAT if we have subtotal\n",
    "        if result['subtotal'] and (not result['vat_amount'] or result['vat_amount'] < 100):\n",
    "            result['vat_amount'] = round(result['subtotal'] * 0.07, 2)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_items_info(self, text: str) -> Dict[str, any]:\n",
    "        \"\"\"Extract item information from text - improved version with better price parsing\"\"\"\n",
    "        result = {\n",
    "            'item_description': None,\n",
    "            'item_quantity': None,\n",
    "            'item_unit_price': None\n",
    "        }\n",
    "        \n",
    "        # Look for column format data (extracted from tables)\n",
    "        column_pattern = r'([^:]+):\\s*([^:\\n]+)'\n",
    "        columns = re.findall(column_pattern, text)\n",
    "        \n",
    "        descriptions = []\n",
    "        quantities = []\n",
    "        prices = []\n",
    "        \n",
    "        for column_name, column_values in columns:\n",
    "            column_name = column_name.strip()\n",
    "            \n",
    "            # Check if this is a description column\n",
    "            if any(keyword in column_name.lower() for keyword in ['รายการ', 'item', 'description', 'service', 'บริการ', 'รายละเอียด']):\n",
    "                # Clean up the values\n",
    "                items = [item.strip() for item in column_values.split(',') if item.strip()]\n",
    "                # Filter out non-descriptive items\n",
    "                valid_items = []\n",
    "                for item in items:\n",
    "                    # Skip items that are mostly numbers or too short\n",
    "                    if len(item) > 5 and not re.match(r'^\\d+$', item) and 'เลข' not in item:\n",
    "                        valid_items.append(item)\n",
    "                descriptions.extend(valid_items)\n",
    "            \n",
    "            # Check if this is a quantity column\n",
    "            elif any(keyword in column_name.lower() for keyword in ['จำนวน', 'quantity', 'qty']):\n",
    "                items = column_values.split(',')\n",
    "                for item in items:\n",
    "                    item = item.strip()\n",
    "                    # Extract numbers that look like quantities (typically small integers)\n",
    "                    numbers = re.findall(r'\\b(\\d+)\\b', item)\n",
    "                    for num in numbers:\n",
    "                        if 1 <= int(num) <= 1000:  # Reasonable quantity range\n",
    "                            quantities.append(int(num))\n",
    "            \n",
    "            # Check if this is a unit price column - more specific pattern\n",
    "            elif any(keyword in column_name.lower() for keyword in ['ราคาต่อหน่วย', 'unit price', 'หน่วยละ']):\n",
    "                items = column_values.split(',')\n",
    "                for item in items:\n",
    "                    item = item.strip()\n",
    "                    # Extract price numbers with proper formatting\n",
    "                    numbers = re.findall(r'(\\d+(?:\\.\\d{2})?)', item)\n",
    "                    for num in numbers:\n",
    "                        try:\n",
    "                            price = float(num)\n",
    "                            if price > 0:\n",
    "                                prices.append(price)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "            \n",
    "            # Check if this is a total price column\n",
    "            elif any(keyword in column_name.lower() for keyword in ['ราคารวม', 'total', 'amount']):\n",
    "                # Don't use total prices for unit price calculation\n",
    "                pass\n",
    "        \n",
    "        # Assign results\n",
    "        if descriptions:\n",
    "            # Take only meaningful descriptions (not system text)\n",
    "            meaningful_descriptions = []\n",
    "            for desc in descriptions:\n",
    "                # Filter out common OCR artifacts and system text\n",
    "                if not any(skip_word in desc.lower() for skip_word in [\n",
    "                    'เลข', 'วันที่', 'ครบกำหนด', 'อ้างอิง', 'เบอร์โทร', 'บาท', \n",
    "                    'vat', 'ภาษี', 'รวม', 'ยอด', 'เอกสาร'\n",
    "                ]) and len(desc.strip()) > 8:\n",
    "                    meaningful_descriptions.append(desc.strip())\n",
    "            \n",
    "            if meaningful_descriptions:\n",
    "                result['item_description'] = ', '.join(meaningful_descriptions[:3])  # Limit to 3 items\n",
    "        \n",
    "        if quantities:\n",
    "            result['item_quantity'] = sum(quantities)\n",
    "        \n",
    "        if prices:\n",
    "            if len(prices) == 1:\n",
    "                # only one price\n",
    "                result['item_unit_price'] = prices[0]\n",
    "            else:\n",
    "                # multiprices - not define unit price\n",
    "                result['item_unit_price'] = None\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_comprehensive_fields(self, text: str) -> Dict:\n",
    "        \"\"\"Extract all document fields from text\"\"\"\n",
    "        fields = {\n",
    "            'document_no': None,\n",
    "            'document_date': None,\n",
    "            'due_date': None,\n",
    "            'seller_name': None,\n",
    "            'seller_tax_id': None,\n",
    "            'buyer_name': None,\n",
    "            'buyer_tax_id': None,\n",
    "            'subtotal': None,\n",
    "            'vat_amount': None,\n",
    "            'total_amount': None,\n",
    "            'item_description': None,\n",
    "            'item_quantity': None,\n",
    "            'item_unit_price': None\n",
    "        }\n",
    "        \n",
    "        # Extract document number\n",
    "        fields['document_no'] = self.extract_document_numbers(text)\n",
    "        \n",
    "        # Extract dates\n",
    "        dates = self.extract_dates(text)\n",
    "        fields['document_date'] = dates['document_date']\n",
    "        fields['due_date'] = dates['due_date']\n",
    "        \n",
    "        # Extract entities\n",
    "        entities = self.extract_entities(text)\n",
    "        fields.update(entities)\n",
    "        \n",
    "        # Extract amounts\n",
    "        amounts = self.extract_amounts(text)\n",
    "        fields.update(amounts)\n",
    "        \n",
    "        # Extract items\n",
    "        items = self.extract_items_info(text)\n",
    "        fields.update(items)\n",
    "        \n",
    "        return fields\n",
    "    \n",
    "    def save_to_json(self, doc_data: Dict, doc_type: str):\n",
    "        \"\"\"Save document data to JSON file with error handling - OVERWRITE mode\"\"\"\n",
    "        try:\n",
    "            # Create new data structure with only the current document\n",
    "            data = {\n",
    "                \"invoices\": [],\n",
    "                \"receipts\": [],\n",
    "                \"processing_history\": []\n",
    "            }\n",
    "            \n",
    "            # Add timestamp and ID\n",
    "            doc_data['processed_timestamp'] = datetime.now().isoformat()\n",
    "            doc_data['processing_id'] = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "            \n",
    "            # Add to appropriate section\n",
    "            if doc_type == 'invoice':\n",
    "                data['invoices'].append(doc_data)\n",
    "            else:\n",
    "                data['receipts'].append(doc_data)\n",
    "            \n",
    "            # Add to processing history\n",
    "            data['processing_history'].append({\n",
    "                'timestamp': doc_data['processed_timestamp'],\n",
    "                'type': doc_type,\n",
    "                'processing_id': doc_data['processing_id']\n",
    "            })\n",
    "            \n",
    "            # OVERWRITE the JSON file completely\n",
    "            with open(self.json_storage_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "            print(f\"Overwritten JSON: {doc_type} - {doc_data['processing_id']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to JSON: {e}\")\n",
    "            # Try to create a backup\n",
    "            try:\n",
    "                backup_data = {doc_type: [doc_data], \"processing_history\": []}\n",
    "                backup_path = self.json_storage_path.replace('.json', '_backup.json')\n",
    "                with open(backup_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(backup_data, f, ensure_ascii=False, indent=2)\n",
    "                print(f\"Created backup at: {backup_path}\")\n",
    "            except:\n",
    "                print(\"Could not create backup file\")\n",
    "    \n",
    "    def append_to_csv(self, doc_data: Dict, doc_type: str):\n",
    "        \"\"\"Append document data to CSV file\"\"\"\n",
    "        try:\n",
    "            csv_path = self.invoice_csv_path if doc_type == 'invoice' else self.receipt_csv_path\n",
    "            \n",
    "            # Read existing CSV\n",
    "            if os.path.exists(csv_path):\n",
    "                df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "            else:\n",
    "                df = pd.DataFrame()\n",
    "            \n",
    "            # Create new row\n",
    "            new_row = pd.DataFrame([doc_data])\n",
    "            \n",
    "            # Append to existing data\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            \n",
    "            # Save back to CSV\n",
    "            df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "            \n",
    "            print(f\"Appended to CSV: {csv_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error appending to CSV: {e}\")\n",
    "    \n",
    "    def process_text_file(self, text_file_path: str):\n",
    "        \"\"\"\n",
    "        Process a text file to extract document information\n",
    "        \n",
    "        Args:\n",
    "            text_file_path (str): Path to the text file\n",
    "        \"\"\"\n",
    "        print(f\"Processing text file: {text_file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Read text file\n",
    "            with open(text_file_path, 'r', encoding='utf-8') as f:\n",
    "                text_content = f.read()\n",
    "            \n",
    "            if not text_content.strip():\n",
    "                print(\"Text file is empty\")\n",
    "                return\n",
    "            \n",
    "            # Classify document type\n",
    "            doc_type = self.classify_document(text_content)\n",
    "            print(f\"Document classified as: {doc_type.upper()}\")\n",
    "            \n",
    "            # Extract comprehensive fields\n",
    "            extracted_fields = self.extract_comprehensive_fields(text_content)\n",
    "            \n",
    "            # Prepare structured data\n",
    "            structured_data = {\n",
    "                'source_file': text_file_path,\n",
    "                'document_type': doc_type,\n",
    "                'processed_timestamp': datetime.now().isoformat(),\n",
    "                'raw_text': text_content\n",
    "            }\n",
    "            \n",
    "            # Add document-specific fields\n",
    "            if doc_type == 'invoice':\n",
    "                structured_data.update({\n",
    "                    'invoice_no': extracted_fields.get('document_no'),\n",
    "                    'invoice_date': extracted_fields.get('document_date'),\n",
    "                    'due_date': extracted_fields.get('due_date'),\n",
    "                    'seller_name': extracted_fields.get('seller_name'),\n",
    "                    'seller_tax_id': extracted_fields.get('seller_tax_id'),\n",
    "                    'buyer_name': extracted_fields.get('buyer_name'),\n",
    "                    'buyer_tax_id': extracted_fields.get('buyer_tax_id'),\n",
    "                    'item_description': extracted_fields.get('item_description'),\n",
    "                    'item_quantity': extracted_fields.get('item_quantity'),\n",
    "                    'item_unit_price': extracted_fields.get('item_unit_price'),\n",
    "                    'subtotal': extracted_fields.get('subtotal'),\n",
    "                    'vat_amount': extracted_fields.get('vat_amount'),\n",
    "                    'total_amount': extracted_fields.get('total_amount'),\n",
    "                    'currency': 'THB',\n",
    "                    'notes': None\n",
    "                })\n",
    "            else:  # receipt\n",
    "                structured_data.update({\n",
    "                    'receipt_no': extracted_fields.get('document_no'),\n",
    "                    'receipt_date': extracted_fields.get('document_date'),\n",
    "                    'seller_name': extracted_fields.get('seller_name'),\n",
    "                    'seller_tax_id': extracted_fields.get('seller_tax_id'),\n",
    "                    'buyer_name': extracted_fields.get('buyer_name'),\n",
    "                    'payment_method': 'cash',  # Default\n",
    "                    'item_description': extracted_fields.get('item_description'),\n",
    "                    'item_quantity': extracted_fields.get('item_quantity'),\n",
    "                    'item_unit_price': extracted_fields.get('item_unit_price'),\n",
    "                    'subtotal': extracted_fields.get('subtotal'),\n",
    "                    'vat_amount': extracted_fields.get('vat_amount'),\n",
    "                    'total_paid': extracted_fields.get('total_amount'),\n",
    "                    'currency': 'THB',\n",
    "                    'acknowledgement': None\n",
    "                })\n",
    "            \n",
    "            # Display extracted information\n",
    "            print(f\"\\nExtracted Information:\")\n",
    "            print(f\"   Document No: {structured_data.get('invoice_no' if doc_type == 'invoice' else 'receipt_no')}\")\n",
    "            print(f\"   Date: {structured_data.get('invoice_date' if doc_type == 'invoice' else 'receipt_date')}\")\n",
    "            print(f\"   Seller: {structured_data.get('seller_name')}\")\n",
    "            print(f\"   Total: {structured_data.get('total_amount' if doc_type == 'invoice' else 'total_paid')}\")\n",
    "            print(f\"   Items: {structured_data.get('item_description', 'None')}\")\n",
    "            \n",
    "            # Save to JSON\n",
    "            self.save_to_json(structured_data, doc_type)\n",
    "            \n",
    "            # Save to CSV\n",
    "            self.append_to_csv(structured_data, doc_type)\n",
    "            \n",
    "            print(f\"Document processed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text file: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def display_summary(self):\n",
    "        \"\"\"Display processing summary with error handling\"\"\"\n",
    "        try:\n",
    "            # Try to load JSON data\n",
    "            try:\n",
    "                with open(self.json_storage_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                print(\"JSON file corrupted or missing, cannot display summary\")\n",
    "                return\n",
    "            \n",
    "            invoices = data.get('invoices', [])\n",
    "            receipts = data.get('receipts', [])\n",
    "            \n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(\"TEXT DOCUMENT PROCESSING SUMMARY\")\n",
    "            print(f\"{'=' * 60}\")\n",
    "            print(f\"Total Documents Processed: {len(invoices) + len(receipts)}\")\n",
    "            print(f\"Invoices: {len(invoices)}\")\n",
    "            print(f\"Receipts: {len(receipts)}\")\n",
    "            \n",
    "            if invoices:\n",
    "                print(f\"\\nLatest Invoice:\")\n",
    "                latest = invoices[-1]\n",
    "                for key, value in latest.items():\n",
    "                    if value and key not in ['raw_text', 'processing_id']:\n",
    "                        print(f\"  {key}: {value}\")\n",
    "            \n",
    "            if receipts:\n",
    "                print(f\"\\nLatest Receipt:\")\n",
    "                latest = receipts[-1]\n",
    "                for key, value in latest.items():\n",
    "                    if value and key not in ['raw_text', 'processing_id']:\n",
    "                        print(f\"  {key}: {value}\")\n",
    "            \n",
    "            print(f\"\\nOutput Files:\")\n",
    "            print(f\"  JSON: {self.json_storage_path}\")\n",
    "            print(f\"  Invoice CSV: {self.invoice_csv_path}\")\n",
    "            print(f\"  Receipt CSV: {self.receipt_csv_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying summary: {e}\")\n",
    "            print(\"Attempting to show file status...\")\n",
    "            for path in [self.json_storage_path, self.invoice_csv_path, self.receipt_csv_path]:\n",
    "                if os.path.exists(path):\n",
    "                    size = os.path.getsize(path)\n",
    "                    print(f\"  {path}: {size} bytes\")\n",
    "                else:\n",
    "                    print(f\"  {path}: Not found\")\n",
    "\n",
    "\n",
    "def process_document_from_text(text_file_path: str = \"../temp/detected/doc_content.txt\"):\n",
    "    \"\"\"\n",
    "    Main function to process document from text file\n",
    "    \n",
    "    Args:\n",
    "        text_file_path (str): Path to text file\n",
    "    \"\"\"\n",
    "    print(\"TEXT DOCUMENT PROCESSOR\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not os.path.exists(text_file_path):\n",
    "        print(f\"Text file not found: {text_file_path}\")\n",
    "        return\n",
    "    \n",
    "    processor = TextDocumentProcessor()\n",
    "    processor.process_text_file(text_file_path)\n",
    "    processor.display_summary()\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the default text file\n",
    "    process_document_from_text()\n",
    "    \n",
    "    # Or process a specific file\n",
    "    # process_document_from_text(\"path/to/your/text/file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80cea112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoice_no              object\n",
      "invoice_date            object\n",
      "due_date                object\n",
      "seller_name             object\n",
      "seller_tax_id            int64\n",
      "buyer_name              object\n",
      "buyer_tax_id             int64\n",
      "item_description        object\n",
      "item_quantity            int64\n",
      "item_unit_price        float64\n",
      "subtotal               float64\n",
      "vat_amount             float64\n",
      "total_amount           float64\n",
      "currency                object\n",
      "notes                  float64\n",
      "processed_timestamp     object\n",
      "source_file             object\n",
      "document_type           object\n",
      "raw_text                object\n",
      "processing_id           object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>seller_name</th>\n",
       "      <th>seller_tax_id</th>\n",
       "      <th>buyer_name</th>\n",
       "      <th>buyer_tax_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>item_quantity</th>\n",
       "      <th>item_unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>vat_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>notes</th>\n",
       "      <th>processed_timestamp</th>\n",
       "      <th>source_file</th>\n",
       "      <th>document_type</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>processing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8l202510003</td>\n",
       "      <td>17/09/2025</td>\n",
       "      <td>11/09/2025</td>\n",
       "      <td>บริษัทโกลบอลโซลูชัน จำกัด</td>\n",
       "      <td>105559999999</td>\n",
       "      <td>บริษัท ดิจิทัลเทคโนโลยีไทย จำกัด</td>\n",
       "      <td>105558888888</td>\n",
       "      <td>ค่าบริการดูแลระบบ cloud, ค่าออกแบบเว็ปไซต์ใหม่</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>53500.0</td>\n",
       "      <td>THB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-22T18:16:23.395753</td>\n",
       "      <td>../temp/detected/doc_content.txt</td>\n",
       "      <td>invoice</td>\n",
       "      <td>logo\\nผู้ขาย (เผู้ออกใบแจ้งหนี้)\\nใบแจ้งหนี้\\n...</td>\n",
       "      <td>20250922_181623_395753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    invoice_no invoice_date    due_date                seller_name  \\\n",
       "0  8l202510003   17/09/2025  11/09/2025  บริษัทโกลบอลโซลูชัน จำกัด   \n",
       "\n",
       "   seller_tax_id                        buyer_name  buyer_tax_id  \\\n",
       "0   105559999999  บริษัท ดิจิทัลเทคโนโลยีไทย จำกัด  105558888888   \n",
       "\n",
       "                                 item_description  item_quantity  \\\n",
       "0  ค่าบริการดูแลระบบ cloud, ค่าออกแบบเว็ปไซต์ใหม่              2   \n",
       "\n",
       "   item_unit_price  subtotal  vat_amount  total_amount currency  notes  \\\n",
       "0              NaN   50000.0      3500.0       53500.0      THB    NaN   \n",
       "\n",
       "          processed_timestamp                       source_file document_type  \\\n",
       "0  2025-09-22T18:16:23.395753  ../temp/detected/doc_content.txt       invoice   \n",
       "\n",
       "                                            raw_text           processing_id  \n",
       "0  logo\\nผู้ขาย (เผู้ออกใบแจ้งหนี้)\\nใบแจ้งหนี้\\n...  20250922_181623_395753  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../csv_classifier/invoice_ocr.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "print(df.dtypes)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c64866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
